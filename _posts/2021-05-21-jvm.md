---
layout: post
title: JVM
date:   2021-05-21 15:00:00 -0700
categories: reference
tag: java
---

* content
{:toc}



## JVM Commons

__Common Options__
* Standard Option
* Non-standard Option (-X), `-Xms100M -Xmx100M`
* Advanced Runtime Option (-XX), `-XX:+PrintFlagsFinal`

__Common Commands__
```shell
> javac *.java # generate *.class
> javap -p -v *.class # print out an human readable interpretation similar to Assembly
> jps # check for jvm-running processes 
> jinfo -flag MaxHeapSize [pid] # check specific option
> jinfo -flags [pid] # check all options
> jstat -class [pid] 500 10 # check for class loading and unloading activities
> jstat -gc [pid] 500 10 # check for gc activities
> jstack [pid] # check for deadlocks
> jmap -heap [pid] # check for heap usage snapshot
```

## Class Loading

Class Loading requires an external program __ClassLoader__ that puts *.class into JVM.
* Loading
  * Take in *.class files as `ByteStreams` and initialize __method area__
  * Generate corresponding `Class` objects in heap, allowing for runtime access to encapsulated data. 
* Linking
  * Verification
    * ensures that the binary representation of a class or interface is structurally correct
  * Preparation
    * creating the static fields for a class or interface and initializing such fields to their default values 
  * Resolution
    * the process of dynamically determining concrete values __by memory__ from symbolic references in the run-time constant pool
* Initializing
  * class initialization

__Static Constant Pool__ is the most important part represented in *.class files. It is a table of structures representing various string constants, class and interface names, field names, and other constants that are referred to within the ClassFile structure and its substructures. The format of each constant_pool table entry is indicated by its first "tag" byte.

__What happens when developers' code contains the same class as java.lang.* ?__
Both default and customized class loaders follow __parents delegation__ pattern when `loadClass`, as the following example shows. 

When loading classes, parent implementation always takes higher priority. 

| Class Loader | Loading Scope | Priority | Note |
| :----: | :----: | :----: | :----: |
| BootstrapClassLoader | jre/lib/rt.jar | 0 | written in C |
| ExtClassLoader |  jre/lib/*.jar | 1 | extends BootstrapClassLoader |
| AppClassLoader |  Djava.class.path/*.jar | 2 | extends ExtClassLoader |
| CustomClassLoader | undefined | 3 | |

```java
public abstract class ClassLoader {
    
    // ... omit other implementations 

    protected Class<?> loadClass(String name, boolean resolve)
        throws ClassNotFoundException
    {
        synchronized (getClassLoadingLock(name)) {
            // First, check if the class has already been loaded
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    if (parent != null) {
                        c = parent.loadClass(name, false);
                    } else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    }
}
```

## Runtime Data Area

__Method Area__
* It is created on JVM start-up, shared among all threads
* It stores per-class data structures such as the run-time constant pool, field and method data

__Heap__
* Check [Heap and GC](#heap-and-gc).

__Java Method Stacks__
* It is created at the same time as a thread, private to the thread
* It consists of frames, which contains
    * local variables
    * operand stacks
    * dynamic linking
        * translating these symbolic method references into concrete method references
        * loading classes as necessary to resolve as-yet-undefined symbols
        * translates variable accesses into appropriate offsets in storage structures associated with the run-time location of these variables
    * 
* Native Method Stacks
* The pc Register, aka program counter
    * created at the same time as a thread, private to the thread
    * contains the address of the JVM instruction currently being executed

![]({{ '/styles/images/jvm/runtime-data-area.png' | prepend: site.baseurl }})

## Heap and GC

The part of the __heap__ memory managed by GC is divided into __yound generation and old generation__. Their default allocation ratio is 1:2. Young generation is further divided into __Eden, S0 and S1__. Their default allocation ratio is 8:1:1. __Minor GC__ runs whenever Eden is about to reach capacity. __Major GC__ runs whenever old generation is about to reach capacity. Newly created object always goes to Eden unless it cannot fit in, in which case it goes to old generation directly.

__Full GC__ `System.gc()` = minor GC + major GC + MetaSpace GC (historically known as PermGen space GC). Note that __PermGen__ (before Java 8) is allocated within JVM memory. However __MetaSpace__ (After Java 8) is allocated as part of the main/native memory by calling JNI at the system level. It reduces PermGen OOM because it's difficult to estimate how much PermGen space is needed before running a program. 

__What triggers a minor GC?__  
Minor GC will be triggered by any of the Eden, S0, S1 running out of capacity.

__When an object will be moved from young generation to old generation?__  
When an object is still referenced after 15 minor GC. Why 15? Because the age attribute of every object is only 4-bit.

__Why dividing heap memory into young generation and old generation?__  
Full GC is expensive as it scans all the heap space. However 98% of the objects are short-lived. That's why it is often sufficient and less expensive to have a smaller space as young generation and conduct minor GC (scan only young generation).

__Why young generation is further divided into Eden, S0 and S1?__  
Imagine without S0 and S1, after several GCs, the young generation memory space will be heavily fragmented (objects of various sizes are freed randomly). Now with S0 and S1, the first GC moves the "live" objects from Eden to S0. The second GC moves the "live" objects from Eden and S0 to S1. The third GC moves the "live" objects from Eden and S1 to S0 again....so that after each GC, Eden and one of the survivor area are always clean. 

![]({{ '/styles/images/jvm/gc-flow.png' | prepend: site.baseurl }})

## GC Algorithms

__Generally, there are two stages in a GC algorithms__
* Mark Stage
    * Reference counting algorithm fails at circular reference, causing memory leak.
    * Reachability analysis algorithm (root finding algorithm)
        * Description: Starting from GC root, traverse by DFS and mark all the reachable objects.
        * GC root includes: 
            * local variable
            * static variable
            * constant
            * JNI
* Clean Stage
    * often causing memory fragmentation depending on how it is done

_Note that application is suspended during GC. Newer garbage collectors, such as G1, tend to have reduced suspension time._

__Specifically, JVM adopted GC algorithms are__
* Mark-Sweep Algorithm
    * Traverse, mark the "live" objects, clean the "dead" objects
    * Memory Fragmentation

* Copy Algorithm
    * Traverse, move the "live" objects to new space, clean the old space
    * Given default ratio 8:1:1 in young generation, 1/10 memory is wasted

* Mark-Compact Algorithm
    * Traverse, mark the "live" objects, clean the "dead" objects, re-organize the "live" objects to avoid fragmentation
    * One of the commonly used compact technique is "sliding" all "live" objects to one end of the heap, overwriting "dead" ones
    * Longer suspension time

__Implemenation-wise, JVM has different GC collectors implement different algorithms__
* Serial collector implements copy algorithm
    * single-threaded, long suspension time, used in minor GC
* Serial Old collector implements mark-compact algorithm
    * single-threaded, long suspension time, used in major GC
* ParNew collector implements multi-threaded version of Serial collector
    * exploiting multi-core hardware to reduce suspension time

* Parallel Scavenge implements copy algorithm
    * multi-threaded, reduced suspension time, used in minor GC
    * focusing on improving throughput (throughput = app runtime / (app runtime + gc time))
* Parallel Od, implements mark-compact algorithm
    * multi-threaded, reduced suspension time, used in major GC
    * focusing on improving throughput (throughput = app runtime / (app runtime + gc time))

* CMS (Concurrent Mark Sweep) implements mark-sweep algorithm
    * initial mark: find all GC roots and their directly pointed objects
    * concurrent mark: multi-threaded, allow app thread to interrupt
    * re-mark: some references are modified, re-mark those objects, doesn't allow app threads to interrupt???
    * concurrent sweep

* G1 (Garbage First) allows users to specify desired suspension time
    * divide the heap into 2048 regions
        * Eden Region
        * S0, S1 Region
        * Old Region
        * Humongous Region
        * Empty Region
    * each region is evaluated and prioritized according to its occupancy
    * given specified suspension time, regions will be GC'ed according to their priorities
    * reduced suspension time means quicker response
    * increased GC invocation means lower throughput

* ZGC
    * experimenting in JDK 11

__Concurrent Mark Sweep__
![]({{ '/styles/images/jvm/concurrent-mark-sweep.png' | prepend: site.baseurl }})

__G1 Heap__
![]({{ '/styles/images/jvm/g1-heap.png' | prepend: site.baseurl }})

## Case Study

In a high-concurrency transaction scenario (black Friday sales), backend servers are more likely to see the following issues co-occurring:
* OOM
* GC rate over limit (probably due to memory leak)
* CPU too high
  * jstack check for deadlock
  * jmap check heap usage

![]({{ '/styles/images/jvm/case-study.png' | prepend: site.baseurl }})

__How much memory space does an object take?__  
![]({{ '/styles/images/jvm/how-much-memory-does-an-object-take.png' | prepend: site.baseurl }})

__What is memory alignment?__  
Memory alignment means putting the data in memory at address equal to some multiple of the word size.

![]({{ '/styles/images/jvm/why-memory-alignment-1.png' | prepend: site.baseurl }})
![]({{ '/styles/images/jvm/why-memory-alignment-2.png' | prepend: site.baseurl }})

## Other References

[JVM Master Notes]({{ site.baseurl }}/assets/jvm-master-notes.pdf)

[JVM Internals](https://blog.jamesdbloom.com/JVMInternals.html)

[Java Platform](https://docs.oracle.com/javase/8/docs/index.html)



__Unsolved Questions__

1. During CMS GC, re-mark and sweep steps are concurrent. Does it enforce "Stop The World"? If not, how does it make sure all the objects are correctly marked?

2. In GC copy algorithm, it just moves pointers to place a "live" object to new space, instead of making deep copies? If so, how does it solve memory fragmentation issue?

